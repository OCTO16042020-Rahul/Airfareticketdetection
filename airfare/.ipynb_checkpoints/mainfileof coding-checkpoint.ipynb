{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_set = pd.read_excel(\"Data_Train.xlsx\")\n",
    "test_set = pd.read_excel(\"Test_set.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EDA on Training Set\n",
      "\n",
      "##############################\n",
      "\n",
      "Features/Columns : \n",
      " Index(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n",
      "       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops',\n",
      "       'Additional_Info', 'Price'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Number of Features/Columns :  11\n",
      "\n",
      "Number of Rows :  10683\n",
      "\n",
      "\n",
      "Data Types :\n",
      " Airline            object\n",
      "Date_of_Journey    object\n",
      "Source             object\n",
      "Destination        object\n",
      "Route              object\n",
      "Dep_Time           object\n",
      "Arrival_Time       object\n",
      "Duration           object\n",
      "Total_Stops        object\n",
      "Additional_Info    object\n",
      "Price               int64\n",
      "dtype: object\n",
      "\n",
      " Contains NaN/Empty cells :  True\n",
      "\n",
      " Total empty cells by column :\n",
      " Airline            0\n",
      "Date_of_Journey    0\n",
      "Source             0\n",
      "Destination        0\n",
      "Route              1\n",
      "Dep_Time           0\n",
      "Arrival_Time       0\n",
      "Duration           0\n",
      "Total_Stops        1\n",
      "Additional_Info    0\n",
      "Price              0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "##############################\n",
      "\n",
      "EDA on Test Set\n",
      "\n",
      "##############################\n",
      "\n",
      "Features/Columns : \n",
      " Index(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n",
      "       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops',\n",
      "       'Additional_Info'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Number of Features/Columns :  10\n",
      "\n",
      "Number of Rows :  2671\n",
      "\n",
      "\n",
      "Data Types :\n",
      " Airline            object\n",
      "Date_of_Journey    object\n",
      "Source             object\n",
      "Destination        object\n",
      "Route              object\n",
      "Dep_Time           object\n",
      "Arrival_Time       object\n",
      "Duration           object\n",
      "Total_Stops        object\n",
      "Additional_Info    object\n",
      "dtype: object\n",
      "\n",
      " Contains NaN/Empty cells :  False\n",
      "\n",
      " Total empty cells by column :\n",
      " Airline            0\n",
      "Date_of_Journey    0\n",
      "Source             0\n",
      "Destination        0\n",
      "Route              0\n",
      "Dep_Time           0\n",
      "Arrival_Time       0\n",
      "Duration           0\n",
      "Total_Stops        0\n",
      "Additional_Info    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# chechking the features in the Datasets\n",
    "\n",
    "#Training Set\n",
    "\n",
    "print(\"\\nEDA on Training Set\\n\")\n",
    "print(\"#\"*30)\n",
    "\n",
    "print(\"\\nFeatures/Columns : \\n\", training_set.columns)\n",
    "print(\"\\n\\nNumber of Features/Columns : \", len(training_set.columns))\n",
    "print(\"\\nNumber of Rows : \",len(training_set))\n",
    "print(\"\\n\\nData Types :\\n\", training_set.dtypes)\n",
    "\n",
    "print(\"\\n Contains NaN/Empty cells : \", training_set.isnull().values.any())\n",
    "\n",
    "print(\"\\n Total empty cells by column :\\n\", training_set.isnull().sum(), \"\\n\\n\")\n",
    "\n",
    "\n",
    "# Test Set\n",
    "print(\"#\"*30)\n",
    "print(\"\\nEDA on Test Set\\n\")\n",
    "print(\"#\"*30)\n",
    "\n",
    "\n",
    "print(\"\\nFeatures/Columns : \\n\",test_set.columns)\n",
    "print(\"\\n\\nNumber of Features/Columns : \",len(test_set.columns))\n",
    "print(\"\\nNumber of Rows : \",len(test_set))\n",
    "print(\"\\n\\nData Types :\\n\", test_set.dtypes)\n",
    "print(\"\\n Contains NaN/Empty cells : \", test_set.isnull().values.any())\n",
    "print(\"\\n Total empty cells by column :\\n\", test_set.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length of Training Set :  10683\n",
      "Length of Training Set after dropping NaN:  10682\n"
     ]
    }
   ],
   "source": [
    "# Dealing with the Missing Value\n",
    "\n",
    "print(\"Original Length of Training Set : \", len(training_set))\n",
    "\n",
    "training_set = training_set.dropna()\n",
    "\n",
    "print(\"Length of Training Set after dropping NaN: \", len(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Journey Date \n",
    "\n",
    "#Training Set\n",
    "\n",
    "training_set['Journey_Day'] = pd.to_datetime(training_set.Date_of_Journey, format='%d/%m/%Y').dt.day\n",
    "\n",
    "training_set['Journey_Month'] = pd.to_datetime(training_set.Date_of_Journey, format='%d/%m/%Y').dt.month\n",
    "\n",
    "# Test Set\n",
    "\n",
    "test_set['Journey_Day'] = pd.to_datetime(test_set.Date_of_Journey, format='%d/%m/%Y').dt.day\n",
    "\n",
    "test_set['Journey_Month'] = pd.to_datetime(test_set.Date_of_Journey, format='%d/%m/%Y').dt.month\n",
    "\n",
    "# Compare the dates and delete the original date feature\n",
    "\n",
    "training_set.drop(labels = 'Date_of_Journey', axis = 1, inplace = True)\n",
    "\n",
    "test_set.drop(labels = 'Date_of_Journey', axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Duration\n",
    "\n",
    "# Training Set\n",
    "\n",
    "duration = list(training_set['Duration'])\n",
    "\n",
    "for i in range(len(duration)) :\n",
    "    if len(duration[i].split()) != 2:\n",
    "        if 'h' in duration[i] :\n",
    "            duration[i] = duration[i].strip() + ' 0m'\n",
    "        elif 'm' in duration[i] :\n",
    "            duration[i] = '0h {}'.format(duration[i].strip())\n",
    "\n",
    "dur_hours = []\n",
    "dur_minutes = []  \n",
    "\n",
    "for i in range(len(duration)) :\n",
    "    dur_hours.append(int(duration[i].split()[0][:-1]))\n",
    "    dur_minutes.append(int(duration[i].split()[1][:-1]))\n",
    "    \n",
    "training_set['Duration_hours'] = dur_hours\n",
    "training_set['Duration_minutes'] =dur_minutes\n",
    "\n",
    "training_set.drop(labels = 'Duration', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Test Set\n",
    "\n",
    "durationT = list(test_set['Duration'])\n",
    "\n",
    "for i in range(len(durationT)) :\n",
    "    if len(durationT[i].split()) != 2:\n",
    "        if 'h' in durationT[i] :\n",
    "            durationT[i] = durationT[i].strip() + ' 0m'\n",
    "        elif 'm' in durationT[i] :\n",
    "            durationT[i] = '0h {}'.format(durationT[i].strip())\n",
    "            \n",
    "dur_hours = []\n",
    "dur_minutes = []  \n",
    "\n",
    "for i in range(len(durationT)) :\n",
    "    dur_hours.append(int(durationT[i].split()[0][:-1]))\n",
    "    dur_minutes.append(int(durationT[i].split()[1][:-1]))\n",
    "  \n",
    "    \n",
    "test_set['Duration_hours'] = dur_hours\n",
    "test_set['Duration_minutes'] = dur_minutes\n",
    "\n",
    "test_set.drop(labels = 'Duration', axis = 1, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Departure and Arrival Times\n",
    "\n",
    "# Training Set\n",
    "\n",
    "\n",
    "training_set['Depart_Time_Hour'] = pd.to_datetime(training_set.Dep_Time).dt.hour\n",
    "training_set['Depart_Time_Minutes'] = pd.to_datetime(training_set.Dep_Time).dt.minute\n",
    "\n",
    "training_set.drop(labels = 'Dep_Time', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "training_set['Arr_Time_Hour'] = pd.to_datetime(training_set.Arrival_Time).dt.hour\n",
    "training_set['Arr_Time_Minutes'] = pd.to_datetime(training_set.Arrival_Time).dt.minute\n",
    "\n",
    "training_set.drop(labels = 'Arrival_Time', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Test Set\n",
    "\n",
    "\n",
    "test_set['Depart_Time_Hour'] = pd.to_datetime(test_set.Dep_Time).dt.hour\n",
    "test_set['Depart_Time_Minutes'] = pd.to_datetime(test_set.Dep_Time).dt.minute\n",
    "\n",
    "\n",
    "test_set.drop(labels = 'Dep_Time', axis = 1, inplace = True)\n",
    "\n",
    "test_set['Arr_Time_Hour'] = pd.to_datetime(test_set.Arrival_Time).dt.hour\n",
    "test_set['Arr_Time_Minutes'] = pd.to_datetime(test_set.Arrival_Time).dt.minute\n",
    "\n",
    "test_set.drop(labels = 'Arrival_Time', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent Variable\n",
    "Y_train = training_set.iloc[:,6].values  # 6 is the index of \"Price\" in the Training Set \n",
    "\n",
    "# Independent Variables\n",
    "X_train = training_set.iloc[:,training_set.columns != 'Price'].values # selects all columns except \"Price\"\n",
    "\n",
    "# Independent Variables for Test Set\n",
    "X_test = test_set.iloc[:,:].values\n",
    "\n",
    "Y_test = test_set.iloc[:,6].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "# Training Set    \n",
    "\n",
    "X_train[:,0] = le1.fit_transform(X_train[:,0])\n",
    "\n",
    "X_train[:,1] = le1.fit_transform(X_train[:,1])\n",
    "\n",
    "X_train[:,2] = le1.fit_transform(X_train[:,2])\n",
    "\n",
    "X_train[:,3] = le1.fit_transform(X_train[:,3])\n",
    "\n",
    "X_train[:,4] = le1.fit_transform(X_train[:,4])\n",
    "\n",
    "X_train[:,5] = le1.fit_transform(X_train[:,5])\n",
    "\n",
    "# Test Set\n",
    "\n",
    "\n",
    "X_test[:,0] = le2.fit_transform(X_test[:,0])\n",
    "\n",
    "X_test[:,1] = le2.fit_transform(X_test[:,1])\n",
    "\n",
    "X_test[:,2] = le2.fit_transform(X_test[:,2])\n",
    "\n",
    "X_test[:,3] = le2.fit_transform(X_test[:,3])\n",
    "\n",
    "X_test[:,4] = le2.fit_transform(X_test[:,4])\n",
    "\n",
    "X_test[:,5] = le2.fit_transform(X_test[:,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "#sc_y = StandardScaler()\n",
    "\n",
    "Y_train = Y_train.reshape((len(Y_train), 1)) \n",
    "\n",
    "Y_train = sc_X.fit_transform(Y_train)\n",
    "\n",
    "Y_train = Y_train.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel = \"rbf\")\n",
    "\n",
    "svr.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = sc_X.inverse_transform(svr.predict(X_test))\n",
    "\n",
    "\n",
    "pd.DataFrame(Y_pred, columns = ['Price']).to_excel(\"Final_Pred.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0  10547.002077\n",
      "1   6773.635780\n",
      "2  11482.732670\n",
      "3  11281.247128\n",
      "4   4379.175423\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(Y_pred).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "filename = 'rf_mode.sav'\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "rf.fit(X_train, Y_train);\n",
    "# Train the model on training data\n",
    "pickle.dump(rf, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86081861])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_X.inverse_transform(svr.predict(X_train[0]))\n",
    "\n",
    "#rf.predict(np.array([X_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 12.46 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - Y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.63465262, 12.84296029, 17.50060794, ...,  5.13529212,\n",
       "        5.44939664, 15.31801985])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36534738, -0.84296029,  3.49939206, ...,  0.86470788,\n",
       "        0.55060336, -0.31801985])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.81 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors/ Y_pred)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36534738, -0.84296029,  3.49939206, ...,  0.86470788,\n",
       "        0.55060336, -0.31801985])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
